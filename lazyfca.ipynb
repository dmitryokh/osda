{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def dummy_encode_categorical_columns(data):\n",
    "    result_data = copy.deepcopy(data)\n",
    "    for column in data.columns.values:\n",
    "        result_data = pd.concat([result_data, pd.get_dummies(result_data[column], prefix = column, prefix_sep = ': ')], axis = 1)\n",
    "        del result_data[column]\n",
    "    return result_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_file(name):\n",
    "    df = pd.read_csv(name, sep=',')\n",
    "    df = df.replace(to_replace='positive', value=1)\n",
    "    df = df.replace(to_replace='negative', value=0)\n",
    "    y = np.array(df['V10'])\n",
    "    del df['V10']\n",
    "    bin_df = dummy_encode_categorical_columns(df)\n",
    "    return np.array(bin_df).astype(int), y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('../test1.csv', sep=',')\n",
    "df_train = pd.read_csv('../train1.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pred_data(i, part):\n",
    "    X_train, y_train = parse_file('../train' + str(i) + '.csv')\n",
    "    X_test, y_test = parse_file('../test' + str(i) + '.csv')\n",
    "    X_train_pos = X_train[y_train == 1]\n",
    "    X_train_neg = X_train[y_train == 0]\n",
    "    \n",
    "    y_pred = []\n",
    "\n",
    "    for test_obj in X_test:\n",
    "        pos = 0\n",
    "        neg = 0\n",
    "        for pos_obj in X_train_pos:\n",
    "            if np.sum(test_obj == pos_obj) > int(len(pos_obj) * part):\n",
    "                pos += 1\n",
    "        for neg_obj in X_train_neg:\n",
    "            if np.sum(test_obj == neg_obj) > int(len(neg_obj) * part):\n",
    "                neg += 1\n",
    "\n",
    "        pos = pos / float(len(X_train_pos))\n",
    "        neg = neg / float(len(X_train_neg))\n",
    "        if (pos > neg):\n",
    "            y_pred.append(1)\n",
    "        else:\n",
    "            y_pred.append(0)\n",
    "            \n",
    "    y_pred = np.array(y_pred)\n",
    "    #print y_pred\n",
    "    \n",
    "    '''\n",
    "    TP = np.sum(y_test * y_pred)\n",
    "    TN = np.sum(y_test + y_pred == 0)\n",
    "    FP = np.sum((y_test  == 0) * (y_pred == 1))\n",
    "    FN = np.sum((y_test  == 1) * (y_pred == 0))\n",
    "    TPR = float(TP) / np.sum(y_test == 1)\n",
    "    TNR = float(TN) / np.sum(y_test == 0)\n",
    "    FPR = float(FP) / (TP + FN)\n",
    "    NPV = float(TN) / (TN + FN)\n",
    "    FDR = float(FP) / (TP + FP)\n",
    "    '''\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred)\n",
    "    rec = recall_score(y_test, y_pred)\n",
    "    \n",
    "    print \"Dataset {}\".format(i)\n",
    "    #print \"True Positive: {}\\nTrue Negative: {}\\nFalse Positive: {}\\nFalse Negative: {}\\nTrue Positive Rate: {}\\nTrue Negative Rate: {}\\n\\\n",
    "    #Negative Predictive Value: {}\\nFalse Positive Rate: {}\\nFalse Discovery Rate: {}\\nAccuracy: {}\\nPrecision: {}\\nRecall: {}\".format(TP, TN, FP, FN, TPR, TNR, FPR, NPV, FDR, acc, prec, rec)\n",
    "    print \"Accuracy: {}\\nPrecision: {}\\nRecall: {}\".format(acc, prec, rec)\n",
    "    print(\"===========\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 1\n",
      "Accuracy: 0.47311827957\n",
      "Precision: 0.666666666667\n",
      "Recall: 0.393442622951\n",
      "===========\n",
      "Dataset 2\n",
      "Accuracy: 0.51724137931\n",
      "Precision: 0.595744680851\n",
      "Recall: 0.549019607843\n",
      "===========\n",
      "Dataset 3\n",
      "Accuracy: 0.61\n",
      "Precision: 0.770833333333\n",
      "Recall: 0.569230769231\n",
      "===========\n",
      "Dataset 4\n",
      "Accuracy: 0.516853932584\n",
      "Precision: 0.690476190476\n",
      "Recall: 0.491525423729\n",
      "===========\n",
      "Dataset 5\n",
      "Accuracy: 0.52808988764\n",
      "Precision: 0.717391304348\n",
      "Recall: 0.532258064516\n",
      "===========\n",
      "Dataset 6\n",
      "Accuracy: 0.6\n",
      "Precision: 0.75\n",
      "Recall: 0.589285714286\n",
      "===========\n",
      "Dataset 7\n",
      "Accuracy: 0.570175438596\n",
      "Precision: 0.677966101695\n",
      "Recall: 0.571428571429\n",
      "===========\n",
      "Dataset 8\n",
      "Accuracy: 0.588785046729\n",
      "Precision: 0.737704918033\n",
      "Recall: 0.616438356164\n",
      "===========\n",
      "Dataset 9\n",
      "Accuracy: 0.660194174757\n",
      "Precision: 0.786885245902\n",
      "Recall: 0.685714285714\n",
      "===========\n",
      "Dataset 10\n",
      "Accuracy: 0.516483516484\n",
      "Precision: 0.659574468085\n",
      "Recall: 0.525423728814\n",
      "===========\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 10):\n",
    "    pred_data(i+1, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 1\n",
      "Accuracy: 0.881720430108\n",
      "Precision: 1.0\n",
      "Recall: 0.819672131148\n",
      "===========\n",
      "Dataset 2\n",
      "Accuracy: 0.885057471264\n",
      "Precision: 0.918367346939\n",
      "Recall: 0.882352941176\n",
      "===========\n",
      "Dataset 3\n",
      "Accuracy: 0.91\n",
      "Precision: 0.98275862069\n",
      "Recall: 0.876923076923\n",
      "===========\n",
      "Dataset 4\n",
      "Accuracy: 0.876404494382\n",
      "Precision: 0.961538461538\n",
      "Recall: 0.847457627119\n",
      "===========\n",
      "Dataset 5\n",
      "Accuracy: 0.932584269663\n",
      "Precision: 1.0\n",
      "Recall: 0.903225806452\n",
      "===========\n",
      "Dataset 6\n",
      "Accuracy: 0.870588235294\n",
      "Precision: 0.941176470588\n",
      "Recall: 0.857142857143\n",
      "===========\n",
      "Dataset 7\n",
      "Accuracy: 0.850877192982\n",
      "Precision: 0.964912280702\n",
      "Recall: 0.785714285714\n",
      "===========\n",
      "Dataset 8\n",
      "Accuracy: 0.88785046729\n",
      "Precision: 0.955223880597\n",
      "Recall: 0.876712328767\n",
      "===========\n",
      "Dataset 9\n",
      "Accuracy: 0.854368932039\n",
      "Precision: 0.936507936508\n",
      "Recall: 0.842857142857\n",
      "===========\n",
      "Dataset 10\n",
      "Accuracy: 0.89010989011\n",
      "Precision: 0.980392156863\n",
      "Recall: 0.847457627119\n",
      "===========\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 10):\n",
    "    pred_data(i+1, 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 1\n",
      "Accuracy: 0.344086021505\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "===========\n",
      "Dataset 2\n",
      "Accuracy: 0.413793103448\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "===========\n",
      "Dataset 3\n",
      "Accuracy: 0.35\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "===========\n",
      "Dataset 4\n",
      "Accuracy: 0.337078651685\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "===========\n",
      "Dataset 5\n",
      "Accuracy: 0.303370786517\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "===========\n",
      "Dataset 6\n",
      "Accuracy: 0.341176470588\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "===========\n",
      "Dataset 7\n",
      "Accuracy: 0.385964912281\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "===========\n",
      "Dataset 8\n",
      "Accuracy: 0.317757009346\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "===========\n",
      "Dataset 9\n",
      "Accuracy: 0.320388349515\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "===========\n",
      "Dataset 10\n",
      "Accuracy: 0.351648351648\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "===========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:958: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 10):\n",
    "    pred_data(i+1, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 1\n",
      "Accuracy: 0.451612903226\n",
      "Precision: 0.631578947368\n",
      "Recall: 0.393442622951\n",
      "===========\n",
      "Dataset 2\n",
      "Accuracy: 0.48275862069\n",
      "Precision: 0.5625\n",
      "Recall: 0.529411764706\n",
      "===========\n",
      "Dataset 3\n",
      "Accuracy: 0.54\n",
      "Precision: 0.702127659574\n",
      "Recall: 0.507692307692\n",
      "===========\n",
      "Dataset 4\n",
      "Accuracy: 0.483146067416\n",
      "Precision: 0.658536585366\n",
      "Recall: 0.457627118644\n",
      "===========\n",
      "Dataset 5\n",
      "Accuracy: 0.494382022472\n",
      "Precision: 0.68085106383\n",
      "Recall: 0.516129032258\n",
      "===========\n",
      "Dataset 6\n",
      "Accuracy: 0.552941176471\n",
      "Precision: 0.714285714286\n",
      "Recall: 0.535714285714\n",
      "===========\n",
      "Dataset 7\n",
      "Accuracy: 0.526315789474\n",
      "Precision: 0.637931034483\n",
      "Recall: 0.528571428571\n",
      "===========\n",
      "Dataset 8\n",
      "Accuracy: 0.551401869159\n",
      "Precision: 0.71186440678\n",
      "Recall: 0.575342465753\n",
      "===========\n",
      "Dataset 9\n",
      "Accuracy: 0.572815533981\n",
      "Precision: 0.709677419355\n",
      "Recall: 0.628571428571\n",
      "===========\n",
      "Dataset 10\n",
      "Accuracy: 0.417582417582\n",
      "Precision: 0.568181818182\n",
      "Recall: 0.423728813559\n",
      "===========\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 10):\n",
    "    pred_data(i+1, 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
